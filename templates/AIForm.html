<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dynamic TensorFlow.js Prediction</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
</head>
<body>
    <h1>Dynamic TensorFlow.js Prediction</h1>
    <div id="loading" style="display:none;">Loading model, please wait...</div>
    <div id="error" style="display:none; color: red;">Error loading the model. Please try again.</div>
    <video id="webcam" autoplay width="640" height="480"></video>
    <div id="prediction"></div>
    <video id="webcam" autoplay width="640" height="480"></video>
    <div id="prediction"></div>
    
    <script>
        document.addEventListener('DOMContentLoaded', async () => {
            const urlParams = new URLSearchParams(window.location.search);
            const modelType = urlParams.get('model') || 'model_jab.json';
            
            const modelPath = `/static/model/${modelType}`;
            console.log('Loading model from:', modelPath);
            
            // Show the loading message
            document.getElementById('loading').style.display = 'block';

            // Attempt to load the model
            const model = await tf.loadLayersModel(modelPath).catch(e => {
                console.error('Error loading the model:', e);
                document.getElementById('loading').style.display = 'none';
                document.getElementById('error').style.display = 'block';
                return null;
            });

            if (model) {
                console.log('Model loaded');
                document.getElementById('loading').style.display = 'none'; // Hide loading message
                await startWebcam();
                await predictLoop(model);
            }
        });
        async function startWebcam() {
            try {
                const video = document.getElementById('webcam');
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
                await new Promise(resolve => video.onloadedmetadata = resolve); // Wait until the video stream is ready
                console.log("Webcam successfully started");
            } catch (error) {
                console.error('Error accessing the webcam: ', error);
            }
        }


        async function predictLoop(model) {
            const video = document.getElementById('webcam');
            while (true) {
                const prediction = await predict(video, model);
                document.getElementById('prediction').innerText = `Prediction: ${prediction}`;
                await tf.nextFrame(); // Wait for the next frame
            }
        }

        async function predict(videoElement, model) {
            try {
                const tensor = tf.browser.fromPixels(videoElement)
                                        .resizeNearestNeighbor([224, 224]) // Resize to match model input requirements
                                        .toFloat()
                                        .div(tf.scalar(127.5))
                                        .sub(tf.scalar(1))
                                        .expandDims();
                const predictions = await model.predict(tensor).data();
                return predictions; // Customize based on how your model outputs predictions
            } catch (error) {
                console.error("Prediction error:", error);
                return []; // Return an empty array or some error indication
            }
        }

    </script>
</body>
</html>
